#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çˆ¬è™«åŠŸèƒ½æµ‹è¯•è„šæœ¬
"""

import os
import sys
from sehuatang_crawler import SehuatangCrawler

def test_crawler():
    """æµ‹è¯•çˆ¬è™«åŠŸèƒ½"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•çˆ¬è™«åŠŸèƒ½...")
    
    # è®¾ç½®ä»£ç†ï¼ˆå¦‚æœéœ€è¦ï¼‰
    proxy = os.getenv('HTTP_PROXY') or os.getenv('HTTPS_PROXY')
    if proxy:
        print(f"ğŸ”— ä½¿ç”¨ä»£ç†: {proxy}")
    
    # åˆ›å»ºçˆ¬è™«å®ä¾‹
    crawler = SehuatangCrawler(proxy=proxy)
    
    # æµ‹è¯•è·å–è®ºå›åˆ—è¡¨
    print("\nğŸ“‹ æµ‹è¯•è·å–è®ºå›åˆ—è¡¨...")
    try:
        posts = crawler.get_forum_list("2")  # äºšæ´²æ— ç åŒº
        if posts:
            print(f"âœ… æˆåŠŸè·å– {len(posts)} ä¸ªå¸–å­")
            print(f"ğŸ“ ç¬¬ä¸€ä¸ªå¸–å­: {posts[0]['title']}")
        else:
            print("âŒ æœªè·å–åˆ°å¸–å­")
            return False
    except Exception as e:
        print(f"âŒ è·å–è®ºå›åˆ—è¡¨å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•çˆ¬å–å•ä¸ªå¸–å­
    print("\nğŸ“„ æµ‹è¯•çˆ¬å–å•ä¸ªå¸–å­...")
    if posts:
        try:
            post_data = crawler.get_post_content(posts[0]['url'])
            if post_data:
                print(f"âœ… æˆåŠŸçˆ¬å–å¸–å­: {post_data['title']}")
                print(f"ğŸ”¢ ç•ªå·: {post_data.get('code', 'æœªè¯†åˆ«')}")
                print(f"ğŸ“ å¤§å°: {post_data.get('size', 'æœªçŸ¥')}")
                print(f"ğŸ”— ç£åŠ›é“¾æ¥æ•°é‡: {len(post_data.get('magnets', []))}")
                print(f"ğŸ–¼ï¸ å›¾ç‰‡æ•°é‡: {len(post_data.get('images', []))}")
                print(f"ğŸ”“ æ˜¯å¦æœ‰ç : {'æ— ç ' if post_data.get('is_uncensored') else 'æœ‰ç '}")
            else:
                print("âŒ çˆ¬å–å¸–å­å¤±è´¥")
                return False
        except Exception as e:
            print(f"âŒ çˆ¬å–å•ä¸ªå¸–å­å¤±è´¥: {e}")
            return False
    
    print("\nğŸ‰ çˆ¬è™«åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")
    return True

def test_parser_integration():
    """æµ‹è¯•ä¸è§£æå™¨çš„é›†æˆ"""
    print("\nğŸ”— æµ‹è¯•ä¸è§£æå™¨é›†æˆ...")
    
    try:
        from sehuatang_parser import parse_sehuatang_post
        
        # æ¨¡æ‹ŸHTMLå†…å®¹
        test_html = """
        <html>
        <head><title>STARS-123 æµ‹è¯•å½±ç‰‡</title></head>
        <body>
        <td class="t_f">
        STARS-123 æµ‹è¯•å½±ç‰‡ 3.5GB æ— ç æµå‡º
        magnet:?xt=urn:btih:1234567890abcdef1234567890abcdef12345678
        </td>
        </body>
        </html>
        """
        
        result = parse_sehuatang_post(test_html, "http://test.com")
        if result:
            print(f"âœ… è§£ææˆåŠŸ: {result.get('title', 'æœªçŸ¥')}")
            print(f"ğŸ”¢ ç•ªå·: {result.get('code', 'æœªè¯†åˆ«')}")
        else:
            print("âŒ è§£æå¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ è§£æå™¨é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False
    
    return True

if __name__ == "__main__":
    print("ğŸš€ Sehuatang çˆ¬è™«ç³»ç»Ÿæµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•çˆ¬è™«åŠŸèƒ½
    if test_crawler():
        print("âœ… çˆ¬è™«åŠŸèƒ½æµ‹è¯•é€šè¿‡")
    else:
        print("âŒ çˆ¬è™«åŠŸèƒ½æµ‹è¯•å¤±è´¥")
        sys.exit(1)
    
    # æµ‹è¯•è§£æå™¨é›†æˆ
    if test_parser_integration():
        print("âœ… è§£æå™¨é›†æˆæµ‹è¯•é€šè¿‡")
    else:
        print("âŒ è§£æå™¨é›†æˆæµ‹è¯•å¤±è´¥")
        sys.exit(1)
    
    print("\nğŸŠ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå¯ä»¥æ­£å¸¸ä½¿ç”¨ã€‚")
